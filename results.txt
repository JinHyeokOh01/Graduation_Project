==========================================================
MobileNetV1 CPU-NPU Hybrid Inference 실험 결과
==========================================================

1. 성능 (Latency)
----------------------------------------------------------
Method          Time (ms)       Speedup
----------------------------------------------------------
CPU             47.61 ms        1.00x
NPU             2.06 ms         23.21x
Hybrid          7.51 ms         6.34x


2. 정확도 (Accuracy) - 44개 이미지 테스트
----------------------------------------------------------
Method          Top-1           Top-5
----------------------------------------------------------
CPU             29.5% (13/44)   59.1% (26/44)
NPU             27.3% (12/44)   47.7% (21/44)
Hybrid          0.0% (0/44)     0.0% (0/44)
                ※ Quantization calibration 문제


3. 에너지 효율
----------------------------------------------------------
Method          에너지/추론     효율 비율
----------------------------------------------------------
CPU             0.286 J         1.00x
NPU             0.00515 J       55x (95% 절감)
Hybrid          0.030 J         9.5x (89% 절감)


4. 비용 분석 (연간, 100만 추론)
----------------------------------------------------------
환경            비용            비고
----------------------------------------------------------
Edge CPU        65,000원        초기 + 운영 1년
Edge NPU        130,364원       초기 + 운영 1년
Cloud CPU       2,004,480원     GCP n2-standard-4
Cloud TPU       46,656,000원    GCP TPU v2

→ Edge NPU는 Cloud 대비 357배 저렴!


5. 시스템 구성
----------------------------------------------------------
- Hardware: Raspberry Pi 5 (8GB RAM)
- NPU: Hailo-8L (13 TOPS)
- Model: MobileNetV1 (ImageNet)
- Framework: TensorFlow 2.15, Hailo Dataflow Compiler


6. 결론
----------------------------------------------------------
- NPU 단독 실행이 속도(23배), 에너지(55배) 모두 우수
- Hybrid는 CPU 대비 6.3배 빠르지만 정확도 문제 존재
- Edge AI는 클라우드 대비 비용 효율적 (10개월 내 회수)
- 실시간 추론에는 NPU, 범용성 필요 시 Hybrid 권장


실험 일자: 2024-12-17
실험자: 오진혁 (경희대학교 컴퓨터공학과)
==========================================================
